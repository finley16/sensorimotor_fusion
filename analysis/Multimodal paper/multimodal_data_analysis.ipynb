{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import matplotlib\n",
    "import math \n",
    "from matplotlib import rc\n",
    "import sys\n",
    "from scipy.optimize import curve_fit\n",
    "import seaborn as sns\n",
    "\n",
    "# auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('C:\\\\Users\\\\amber\\\\Documents\\\\GitHub\\\\sensorimotor_fusion\\\\analysis\\\\Multimodal paper') # change this for your computer\n",
    "# from supportFile2 import findFFT,plotThingsEO,findFilename,geterr #Momona's code for even and odd trials\n",
    "from globalVars import *\n",
    "from collect_data import findFilename, getrawdata, get_data, analyze\n",
    "fmts = ['svg','pdf']\n",
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon, ttest_rel, friedmanchisquare, shapiro\n",
    "import pickle as pickle\n",
    "from scipy import signal, fft\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "matplotlib.rc('font', **font)\n",
    "takeAvgBA = True\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "python_colors = prop_cycle.by_key()['color'] # python default color cycle\n",
    "\n",
    "DATA_PATH = 'C:\\\\Users\\\\amber\\\\Documents\\\\GitHub\\\\sensorimotor_fusion' #change this for your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from globalVars import *\n",
    "from collect_data import findFilename, getrawdata, get_data, analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data length =  2400\n",
      "primes =  [ 2  3  5  7 11 13 17 19]\n",
      "base freq =  0.05\n",
      "IX =  [ 4  6 10 14 22 26 34 38]\n",
      "Even_IX =  [ 6 14 26 38]\n",
      "Odd_IX =  [ 4 10 22 34]\n",
      "freqs =  [0.1  0.15 0.25 0.35 0.55 0.65 0.85 0.95]\n",
      "omegas =  [0.62831853 0.9424778  1.57079633 2.19911486 3.45575192 4.08407045\n",
      " 5.34070751 5.96902604]\n",
      "T =  40\n",
      "t =  [0.00000000e+00 1.66736140e-02 3.33472280e-02 ... 3.99666528e+01\n",
      " 3.99833264e+01 4.00000000e+01]\n",
      "fs =  60\n",
      "sample_period (dt)=  0.016666666666666666\n",
      "xf =  [0.0000e+00 2.5000e-02 5.0000e-02 ... 2.9925e+01 2.9950e+01 2.9975e+01]\n",
      "Machine =  [-0.7169568 -1.14107219j -0.52958685-0.5619091j  -0.28840044-0.18360142j\n",
      " -0.17134712-0.0779164j  -0.07726649-0.02235881j -0.05656227-0.01384948j\n",
      " -0.03387172-0.00634218j -0.02730057-0.00457371j]\n",
      "scaleInput =  0.04616974606700115\n",
      "scaleOutputScreen =  0.25\n"
     ]
    }
   ],
   "source": [
    "print('data length = ',N)\n",
    "print('primes = ',primes)\n",
    "print('base freq = ',base_freq)\n",
    "print('IX = ',IX)\n",
    "print('Even_IX = ',Even_IX)\n",
    "print('Odd_IX = ',Odd_IX)\n",
    "print('freqs = ',freqs)\n",
    "print('omegas = ',omegas)\n",
    "print('T = ',T) # total time 40 seconds\n",
    "print('t = ',t) # timestamps\n",
    "print('fs = ',fs)\n",
    "print('sample_period (dt)= ',dt)\n",
    "print('xf = ',xf) # frequency domain x-axis, shape (N//2,)\n",
    "print('Machine = ',M)\n",
    "print('scaleInput = ',scaleInput)\n",
    "print('scaleOutputScreen = ',scaleOutputScreen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# participants\n",
    "keys = ['HCPS101','HCPS102','HCPS103','HCPS104','HCPS105','HCPS106','HCPS107','HCPS108','HCPS109','HCPS110','HCPS111','HCPS112','HCPS113','HCPS114','HCPS115']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing data for HCPS101\\HCPS101_slider_ctl\n",
      "analyzing data for HCPS102\\HCPS102_slider_ctl\n",
      "analyzing data for HCPS103\\HCPS103_slider_ctl\n",
      "analyzing data for HCPS104\\HCPS104_slider_ctl\n",
      "analyzing data for HCPS105\\HCPS105_slider_ctl\n",
      "analyzing data for HCPS106\\HCPS106_slider_ctl\n",
      "analyzing data for HCPS107\\HCPS107_slider_ctl\n",
      "analyzing data for HCPS108\\HCPS108_slider_ctl\n",
      "analyzing data for HCPS109\\HCPS109_slider_ctl\n",
      "analyzing data for HCPS110\\HCPS110_slider_ctl\n",
      "analyzing data for HCPS111\\HCPS111_slider_ctl\n",
      "analyzing data for HCPS112\\HCPS112_slider_ctl\n",
      "analyzing data for HCPS113\\HCPS113_slider_ctl\n",
      "analyzing data for HCPS114\\HCPS114_slider_ctl\n",
      "analyzing data for HCPS115\\HCPS115_slider_ctl\n",
      "analyzing data for HCPS101\\HCPS101_slider_ctl2\n",
      "analyzing data for HCPS102\\HCPS102_slider_ctl2\n",
      "analyzing data for HCPS103\\HCPS103_slider_ctl2\n",
      "analyzing data for HCPS104\\HCPS104_slider_ctl2\n",
      "analyzing data for HCPS105\\HCPS105_slider_ctl2\n",
      "analyzing data for HCPS106\\HCPS106_slider_ctl2\n",
      "analyzing data for HCPS107\\HCPS107_slider_ctl2\n",
      "analyzing data for HCPS108\\HCPS108_slider_ctl2\n",
      "analyzing data for HCPS109\\HCPS109_slider_ctl2\n",
      "analyzing data for HCPS110\\HCPS110_slider_ctl2\n",
      "analyzing data for HCPS111\\HCPS111_slider_ctl2\n",
      "analyzing data for HCPS112\\HCPS112_slider_ctl2\n",
      "analyzing data for HCPS113\\HCPS113_slider_ctl2\n",
      "analyzing data for HCPS114\\HCPS114_slider_ctl2\n",
      "analyzing data for HCPS115\\HCPS115_slider_ctl2\n"
     ]
    }
   ],
   "source": [
    "# slider control trials\n",
    "Rs_ctl,Ds_ctl,Us_ctl,U0s_ctl,U1s_ctl,Ys_ctl,rs_ctl,ds_ctl,us_ctl,u0s_ctl,u1s_ctl,ys_ctl,errors_ctl = analyze(DATA_PATH,keys,'_slider_ctl')\n",
    "Rs_ctl2,Ds_ctl2,Us_ctl2,U0s_ctl2,U1s_ctl2,Ys_ctl2,rs_ctl2,ds_ctl2,us_ctl2,u0s_ctl2,u1s_ctl2,ys_ctl2,errors_ctl2 = analyze(DATA_PATH,keys,'_slider_ctl2')\n",
    "\n",
    "# combine the data from the controls, total 14 trials\n",
    "Rs_0 = np.concatenate((Rs_ctl, Rs_ctl2), axis=1)\n",
    "Ds_0 = np.concatenate((Ds_ctl, Ds_ctl2), axis=1)\n",
    "Us_0 = np.concatenate((Us_ctl, Us_ctl2), axis=1)\n",
    "U0s_0 = np.concatenate((U0s_ctl, U0s_ctl2), axis=1)\n",
    "U1s_0 = np.concatenate((U1s_ctl, U1s_ctl2), axis=1)\n",
    "Ys_0 = np.concatenate((Ys_ctl, Ys_ctl2), axis=1)\n",
    "rs_0 = np.concatenate((rs_ctl, rs_ctl2), axis=1)\n",
    "ds_0 = np.concatenate((ds_ctl, ds_ctl2), axis=1)\n",
    "us_0 = np.concatenate((us_ctl, us_ctl2), axis=1)\n",
    "u0s_0 = np.concatenate((u0s_ctl, u0s_ctl2), axis=1)\n",
    "u1s_0 = np.concatenate((u1s_ctl, u1s_ctl2), axis=1)\n",
    "ys_0 = np.concatenate((ys_ctl, ys_ctl2), axis=1)\n",
    "errors_0 = np.concatenate((errors_ctl, errors_ctl2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing data for HCPS101\\HCPS101_emg_ctl\n",
      "analyzing data for HCPS102\\HCPS102_emg_ctl\n",
      "analyzing data for HCPS103\\HCPS103_emg_ctl\n",
      "analyzing data for HCPS104\\HCPS104_emg_ctl\n",
      "analyzing data for HCPS105\\HCPS105_emg_ctl\n",
      "analyzing data for HCPS106\\HCPS106_emg_ctl\n",
      "analyzing data for HCPS107\\HCPS107_emg_ctl\n",
      "analyzing data for HCPS108\\HCPS108_emg_ctl\n",
      "analyzing data for HCPS109\\HCPS109_emg_ctl\n",
      "analyzing data for HCPS110\\HCPS110_emg_ctl\n",
      "analyzing data for HCPS111\\HCPS111_emg_ctl\n",
      "analyzing data for HCPS112\\HCPS112_emg_ctl\n",
      "analyzing data for HCPS113\\HCPS113_emg_ctl\n",
      "analyzing data for HCPS114\\HCPS114_emg_ctl\n",
      "analyzing data for HCPS115\\HCPS115_emg_ctl\n",
      "analyzing data for HCPS101\\HCPS101_emg_ctl2\n",
      "analyzing data for HCPS102\\HCPS102_emg_ctl2\n",
      "analyzing data for HCPS103\\HCPS103_emg_ctl2\n",
      "analyzing data for HCPS104\\HCPS104_emg_ctl2\n",
      "analyzing data for HCPS105\\HCPS105_emg_ctl2\n",
      "analyzing data for HCPS106\\HCPS106_emg_ctl2\n",
      "analyzing data for HCPS107\\HCPS107_emg_ctl2\n",
      "analyzing data for HCPS108\\HCPS108_emg_ctl2\n",
      "analyzing data for HCPS109\\HCPS109_emg_ctl2\n",
      "analyzing data for HCPS110\\HCPS110_emg_ctl2\n",
      "analyzing data for HCPS111\\HCPS111_emg_ctl2\n",
      "analyzing data for HCPS112\\HCPS112_emg_ctl2\n",
      "analyzing data for HCPS113\\HCPS113_emg_ctl2\n",
      "analyzing data for HCPS114\\HCPS114_emg_ctl2\n",
      "analyzing data for HCPS115\\HCPS115_emg_ctl2\n"
     ]
    }
   ],
   "source": [
    "# emg control trials\n",
    "Rs_ctl,Ds_ctl,Us_ctl,U0s_ctl,U1s_ctl,Ys_ctl,rs_ctl,ds_ctl,us_ctl,u0s_ctl,u1s_ctl,ys_ctl,errors_ctl = analyze(DATA_PATH,keys,'_emg_ctl')\n",
    "Rs_ctl2,Ds_ctl2,Us_ctl2,U0s_ctl2,U1s_ctl2,Ys_ctl2,rs_ctl2,ds_ctl2,us_ctl2,u0s_ctl2,u1s_ctl2,ys_ctl2,errors_ctl2 = analyze(DATA_PATH,keys,'_emg_ctl2')\n",
    "\n",
    "# combine the data from the controls, total 14 trials\n",
    "Rs_100 = np.concatenate((Rs_ctl, Rs_ctl2), axis=1)\n",
    "Ds_100 = np.concatenate((Ds_ctl, Ds_ctl2), axis=1)\n",
    "Us_100 = np.concatenate((Us_ctl, Us_ctl2), axis=1)\n",
    "U0s_100 = np.concatenate((U0s_ctl, U0s_ctl2), axis=1)\n",
    "U1s_100 = np.concatenate((U1s_ctl, U1s_ctl2), axis=1)\n",
    "Ys_100 = np.concatenate((Ys_ctl, Ys_ctl2), axis=1)\n",
    "rs_100 = np.concatenate((rs_ctl, rs_ctl2), axis=1)\n",
    "ds_100 = np.concatenate((ds_ctl, ds_ctl2), axis=1)\n",
    "us_100 = np.concatenate((us_ctl, us_ctl2), axis=1)\n",
    "u0s_100 = np.concatenate((u0s_ctl, u0s_ctl2), axis=1)\n",
    "u1s_100 = np.concatenate((u1s_ctl, u1s_ctl2), axis=1)\n",
    "ys_100 = np.concatenate((ys_ctl, ys_ctl2), axis=1)\n",
    "errors_100 = np.concatenate((errors_ctl, errors_ctl2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyzing data for HCPS101\\HCPS101_fusion_emg25\n",
      "analyzing data for HCPS102\\HCPS102_fusion_emg25\n",
      "analyzing data for HCPS103\\HCPS103_fusion_emg25\n",
      "analyzing data for HCPS104\\HCPS104_fusion_emg25\n",
      "analyzing data for HCPS105\\HCPS105_fusion_emg25\n",
      "analyzing data for HCPS106\\HCPS106_fusion_emg25\n",
      "analyzing data for HCPS107\\HCPS107_fusion_emg25\n",
      "analyzing data for HCPS108\\HCPS108_fusion_emg25\n",
      "analyzing data for HCPS109\\HCPS109_fusion_emg25\n",
      "analyzing data for HCPS110\\HCPS110_fusion_emg25\n",
      "analyzing data for HCPS111\\HCPS111_fusion_emg25\n",
      "analyzing data for HCPS112\\HCPS112_fusion_emg25\n",
      "analyzing data for HCPS113\\HCPS113_fusion_emg25\n",
      "analyzing data for HCPS114\\HCPS114_fusion_emg25\n",
      "analyzing data for HCPS115\\HCPS115_fusion_emg25\n",
      "analyzing data for HCPS101\\HCPS101_fusion_emg50\n",
      "analyzing data for HCPS102\\HCPS102_fusion_emg50\n",
      "analyzing data for HCPS103\\HCPS103_fusion_emg50\n",
      "analyzing data for HCPS104\\HCPS104_fusion_emg50\n",
      "analyzing data for HCPS105\\HCPS105_fusion_emg50\n",
      "analyzing data for HCPS106\\HCPS106_fusion_emg50\n",
      "analyzing data for HCPS107\\HCPS107_fusion_emg50\n",
      "analyzing data for HCPS108\\HCPS108_fusion_emg50\n",
      "analyzing data for HCPS109\\HCPS109_fusion_emg50\n",
      "analyzing data for HCPS110\\HCPS110_fusion_emg50\n",
      "analyzing data for HCPS111\\HCPS111_fusion_emg50\n",
      "analyzing data for HCPS112\\HCPS112_fusion_emg50\n",
      "analyzing data for HCPS113\\HCPS113_fusion_emg50\n",
      "analyzing data for HCPS114\\HCPS114_fusion_emg50\n",
      "analyzing data for HCPS115\\HCPS115_fusion_emg50\n",
      "analyzing data for HCPS101\\HCPS101_fusion_emg75\n",
      "analyzing data for HCPS102\\HCPS102_fusion_emg75\n",
      "analyzing data for HCPS103\\HCPS103_fusion_emg75\n",
      "analyzing data for HCPS104\\HCPS104_fusion_emg75\n",
      "analyzing data for HCPS105\\HCPS105_fusion_emg75\n",
      "analyzing data for HCPS106\\HCPS106_fusion_emg75\n",
      "analyzing data for HCPS107\\HCPS107_fusion_emg75\n",
      "analyzing data for HCPS108\\HCPS108_fusion_emg75\n",
      "analyzing data for HCPS109\\HCPS109_fusion_emg75\n",
      "analyzing data for HCPS110\\HCPS110_fusion_emg75\n",
      "analyzing data for HCPS111\\HCPS111_fusion_emg75\n",
      "analyzing data for HCPS112\\HCPS112_fusion_emg75\n",
      "analyzing data for HCPS113\\HCPS113_fusion_emg75\n",
      "analyzing data for HCPS114\\HCPS114_fusion_emg75\n",
      "analyzing data for HCPS115\\HCPS115_fusion_emg75\n"
     ]
    }
   ],
   "source": [
    "# fusion trials emg various percentages\n",
    "Rs_25,Ds_25,Us_25,U0s_25,U1s_25,Ys_25,rs_25,ds_25,us_25,u0s_25,u1s_25,ys_25,errors_25 = analyze(DATA_PATH,keys,'_fusion_emg25')\n",
    "Rs_50,Ds_50,Us_50,U0s_50,U1s_50,Ys_50,rs_50,ds_50,us_50,u0s_50,u1s_50,ys_50,errors_50 = analyze(DATA_PATH,keys,'_fusion_emg50')\n",
    "Rs_75,Ds_75,Us_75,U0s_75,U1s_75,Ys_75,rs_75,ds_75,us_75,u0s_75,u1s_75,ys_75,errors_75 = analyze(DATA_PATH,keys,'_fusion_emg75')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all conditions (alpha = 0, 25, 50, 75, 100), alpha = emg percentage\n",
    "Rs = np.stack((Rs_0, Rs_25, Rs_50, Rs_75, Rs_100), axis=1) \n",
    "Ds = np.stack((Ds_0, Ds_25, Ds_50, Ds_75, Ds_100), axis=1) \n",
    "Us = np.stack((Us_0, Us_25, Us_50, Us_75, Us_100), axis=1)\n",
    "U0s = np.stack((U0s_0, U0s_25, U0s_50, U0s_75, U0s_100), axis=1)\n",
    "U1s = np.stack((U1s_0, U1s_25, U1s_50, U1s_75, U1s_100), axis=1)\n",
    "Ys = np.stack((Ys_0, Ys_25, Ys_50, Ys_75, Ys_100), axis=1)\n",
    "rs = np.stack((rs_0, rs_25, rs_50, rs_75, rs_100), axis=1)\n",
    "ds = np.stack((ds_0, ds_25, ds_50, ds_75, ds_100), axis=1)\n",
    "us = np.stack((us_0, us_25, us_50, us_75, us_100), axis=1)\n",
    "u0s = np.stack((u0s_0, u0s_25, u0s_50, u0s_75, u0s_100), axis=1)\n",
    "u1s = np.stack((u1s_0, u1s_25, u1s_50, u1s_75, u1s_100), axis=1)\n",
    "ys = np.stack((ys_0, ys_25, ys_50, ys_75, ys_100), axis=1)\n",
    "errors = np.stack((errors_0, errors_25, errors_50, errors_75, errors_100), axis=1) # subject x condition x trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 5, 14, 2400)\n",
      "(15, 5, 14, 2400)\n",
      "(15, 5, 14)\n"
     ]
    }
   ],
   "source": [
    "print(Rs.shape) # subject x condition x trial x all freqs\n",
    "print(rs.shape) # subject x condition x trial x timestamps\n",
    "print(errors.shape) # subject x condition x trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_num =  15\n",
      "condition_num (alphas) =  5\n",
      "trial_num =  14\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subject_num = len(keys)\n",
    "condition_num = Rs.shape[1]\n",
    "trial_num = Rs.shape[2]\n",
    "print('subject_num = ',subject_num)\n",
    "print('condition_num (alphas) = ',condition_num)\n",
    "print('trial_num = ',trial_num)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('multimodal_data.pkl', 'rb') as file:\n",
    "#     Rs,Ds,Us,U0s,U1s,Ys,rs,ds,us,u0s,u1s,ys,errors,Tur,Tu0r,Tu1r,Tud,Tu0d,Tu1d,Tyr,Tyd = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tur, Tud, Tyr, Tyd from consecutive trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tranfer_function(R,D,U,type = 'input'): #input_type = 'U', 'U0'(emg in fusion), or 'U1'(slider in fusion) or 'Y' (output)\n",
    "  #find index of simulated freqs: trial 0 is EO (ref - Even, dis - Odd)\n",
    "  # Even_index = (np.where(abs(condition['R'][0]) > 1e-12)[0])[:4] #array([ 6, 14, 26, 38])\n",
    "  # Odd_index = (np.where(abs(condition['D'][0]) > 1e-12)[0])[:4]  #array([ 4, 10, 22, 34])\n",
    "\n",
    "  Odd_index = np.array([ 6, 14, 26, 38])\n",
    "  Even_index = np.array([ 4, 10, 22, 34])\n",
    "\n",
    "  #number of Tur & Tud = half(trials) (1 EO & 1 OE trial together as one)\n",
    "  Tur = np.zeros((math.ceil(trial_num/2),8), dtype=complex) #number of stimulatd freqs = 8\n",
    "  Tud = np.zeros((math.ceil(trial_num/2),8), dtype=complex)\n",
    "\n",
    "  if type == 'input':\n",
    "    scale = scaleInput\n",
    "  else: #'output'\n",
    "    scale = scaleOutputScreen\n",
    "    \n",
    "  # Tur & Tud at simulated freqs\n",
    "  for i in [0, 2, 4, 6, 8, 10, 12]: #even trials\n",
    "      Tur[i//2][1::2] = (U[i][Odd_index]/scale) / (R[i][Odd_index]/scaleOutputScreen)\n",
    "      Tud[i//2][::2] = (U[i][Even_index]/scale) / (D[i][Even_index]/scaleInput)\n",
    "\n",
    "  for i in [1, 3, 5, 7, 9, 11, 13]: #odd trials\n",
    "      Tur[i//2][::2] = (U[i][Even_index]/scale) / (R[i][Even_index]/scaleOutputScreen) \n",
    "      Tud[i//2][1::2] = (U[i][Odd_index]/scale) / (D[i][Odd_index]/scaleInput)\n",
    "\n",
    "  return Tur, Tud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tur = np.zeros((subject_num,condition_num,trial_num//2,len(IX)),dtype=complex) #u_fusion / r\n",
    "Tu0r = np.zeros((subject_num,condition_num,trial_num//2,len(IX)),dtype=complex) #u_emg / r\n",
    "Tu1r = np.zeros((subject_num,condition_num,trial_num//2,len(IX)),dtype=complex) #u_slider / r\n",
    "\n",
    "Tud = np.zeros((subject_num,condition_num,trial_num//2,len(IX)),dtype=complex) #u_fusion / d\n",
    "Tu0d = np.zeros((subject_num,condition_num,trial_num//2,len(IX)),dtype=complex) #u_emg / d\n",
    "Tu1d = np.zeros((subject_num,condition_num,trial_num//2,len(IX)),dtype=complex) #u_slider / d\n",
    "\n",
    "Tyr = np.zeros((subject_num,condition_num,trial_num//2,len(IX)),dtype=complex)\n",
    "Tyd = np.zeros((subject_num,condition_num,trial_num//2,len(IX)),dtype=complex)\n",
    "for sub in range(subject_num):\n",
    "    for cond in range(condition_num):\n",
    "        Tur[sub,cond], Tud[sub,cond] = Tranfer_function(Rs[sub,cond],Ds[sub,cond],Us[sub,cond],'input')\n",
    "        Tu0r[sub,cond], Tu0d[sub,cond] = Tranfer_function(Rs[sub,cond],Ds[sub,cond],U0s[sub,cond],'input')\n",
    "        Tu1r[sub,cond], Tu1d[sub,cond] = Tranfer_function(Rs[sub,cond],Ds[sub,cond],U1s[sub,cond],'input')\n",
    "        Tyr[sub,cond], Tyd[sub,cond] = Tranfer_function(Rs[sub,cond],Ds[sub,cond],Ys[sub,cond],'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.70753322-0.24450403j  0.90571855-0.28124795j  0.73536391-1.00026037j\n",
      " -0.40330806-1.35478339j -0.1789956 -0.18387465j -0.01343717+0.09497156j\n",
      " -0.02859247+0.04598237j -0.10691131-0.06793j   ]\n",
      "[ 7.07533218e-01-2.44504028e-01j -2.43207180e+15-1.03537175e+15j\n",
      "  7.35363911e-01-1.00026037e+00j  2.60502493e+16+1.34624103e+16j\n",
      " -1.78995597e-01-1.83874651e-01j -2.64109671e+14-6.23164597e+14j\n",
      " -2.85924652e-02+4.59823699e-02j  5.85127443e+14+7.99562802e+14j]\n"
     ]
    }
   ],
   "source": [
    "# sanity check code\n",
    "sub = 0\n",
    "cond = 0\n",
    "trial = -1\n",
    "print(Tyr[sub,cond,trial])\n",
    "print(Ys[sub,cond,trial,IX] / Rs[sub,cond,trial,IX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the array to a file\n",
    "ALLdata = [Rs,Ds,Us,U0s,U1s,Ys,rs,ds,us,u0s,u1s,ys,errors,Tur,Tu0r,Tu1r,Tud,Tu0d,Tu1d,Tyr,Tyd]\n",
    "with open('multimodal_data.pkl', 'wb') as file:\n",
    "    pickle.dump(ALLdata, file)\n",
    "\n",
    "# # Load the array from the file\n",
    "# with open('data.pkl', 'rb') as file:\n",
    "#     data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
